
Let's try with all data. Lot of epochs. Early stopping

Name = A series with double convolutional layers
Description = A CNN with 4 sets of consecutive convolutional layers where the first one doubles the channels and the second retains them.
            After each set, a dropout layer and a max pooling layer follow. In the end of the network there is a flatten layer with 8192 nodes.
            The last layers are linear droping the nodes, followed by dropout layers.
        
ConvolutionalNeuralNetwork(
  (_model): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Dropout2d(p=0.2, inplace=False)
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Dropout2d(p=0.2, inplace=False)
    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (16): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (21): ReLU()
    (22): Dropout2d(p=0.2, inplace=False)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU()
    (27): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU()
    (30): Dropout2d(p=0.2, inplace=False)
    (31): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (32): Flatten(start_dim=1, end_dim=-1)
    (33): Linear(in_features=8192, out_features=1024, bias=True)
    (34): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): Dropout(p=0.35, inplace=False)
    (36): Linear(in_features=1024, out_features=128, bias=True)
    (37): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Dropout(p=0.35, inplace=False)
    (39): Linear(in_features=128, out_features=1, bias=True)
  )
)
Epochs = 70
Learning rate = 0.001
Batch size = 128
Weight decay = 0.0001


Training samples: 22499
Validation samples: 1250
Early stopping: Enabled
Image size: 128x128


Epoch [1/70]
Training Loss: 0.6303
Validation Loss: 0.5495
Training Accuracy: 0.6461
Validation Accuracy: 0.7216
Duration: 499.87 seconds


Epoch [2/70]
Training Loss: 0.5224
Validation Loss: 0.4447
Training Accuracy: 0.7420
Validation Accuracy: 0.7872
Duration: 375.52 seconds


Epoch [3/70]
Training Loss: 0.4592
Validation Loss: 0.4072
Training Accuracy: 0.7843
Validation Accuracy: 0.7976
Duration: 379.06 seconds


Epoch [4/70]
Training Loss: 0.4084
Validation Loss: 0.3873
Training Accuracy: 0.8126
Validation Accuracy: 0.8328
Duration: 379.58 seconds


Epoch [5/70]
Training Loss: 0.3663
Validation Loss: 0.3010
Training Accuracy: 0.8393
Validation Accuracy: 0.8632
Duration: 379.59 seconds


Epoch [6/70]
Training Loss: 0.3259
Validation Loss: 0.2820
Training Accuracy: 0.8564
Validation Accuracy: 0.8736
Duration: 379.51 seconds


Epoch [7/70]
Training Loss: 0.2974
Validation Loss: 0.2428
Training Accuracy: 0.8718
Validation Accuracy: 0.8976
Duration: 379.43 seconds


Epoch [8/70]
Training Loss: 0.2737
Validation Loss: 0.2254
Training Accuracy: 0.8828
Validation Accuracy: 0.9048
Duration: 384.30 seconds


Epoch [9/70]
Training Loss: 0.2543
Validation Loss: 0.2147
Training Accuracy: 0.8935
Validation Accuracy: 0.9112
Duration: 378.90 seconds


Epoch [10/70]
Training Loss: 0.2329
Validation Loss: 0.2226
Training Accuracy: 0.9046
Validation Accuracy: 0.9088
Duration: 379.66 seconds


Epoch [11/70]
Training Loss: 0.2194
Validation Loss: 0.2116
Training Accuracy: 0.9081
Validation Accuracy: 0.9192
Duration: 379.38 seconds


Epoch [12/70]
Training Loss: 0.2018
Validation Loss: 0.2092
Training Accuracy: 0.9170
Validation Accuracy: 0.9192
Duration: 379.25 seconds


Epoch [13/70]
Training Loss: 0.1915
Validation Loss: 0.1783
Training Accuracy: 0.9207
Validation Accuracy: 0.9200
Duration: 378.70 seconds


Epoch [14/70]
Training Loss: 0.1797
Validation Loss: 0.1973
Training Accuracy: 0.9273
Validation Accuracy: 0.9232
Duration: 378.48 seconds


Epoch [15/70]
Training Loss: 0.1691
Validation Loss: 0.1804
Training Accuracy: 0.9308
Validation Accuracy: 0.9272
Duration: 378.94 seconds


Epoch [16/70]
Training Loss: 0.1629
Validation Loss: 0.1771
Training Accuracy: 0.9339
Validation Accuracy: 0.9280
Duration: 378.81 seconds


Epoch [17/70]
Training Loss: 0.1482
Validation Loss: 0.1872
Training Accuracy: 0.9405
Validation Accuracy: 0.9288
Duration: 378.94 seconds


Epoch [18/70]
Training Loss: 0.1473
Validation Loss: 0.1856
Training Accuracy: 0.9388
Validation Accuracy: 0.9312
Duration: 378.54 seconds


Epoch [19/70]
Training Loss: 0.1355
Validation Loss: 0.1662
Training Accuracy: 0.9454
Validation Accuracy: 0.9400
Duration: 378.59 seconds


Epoch [20/70]
Training Loss: 0.1290
Validation Loss: 0.1997
Training Accuracy: 0.9482
Validation Accuracy: 0.9184
Duration: 379.35 seconds


Epoch [21/70]
Training Loss: 0.1218
Validation Loss: 0.1548
Training Accuracy: 0.9519
Validation Accuracy: 0.9448
Duration: 379.57 seconds


Epoch [22/70]
Training Loss: 0.1175
Validation Loss: 0.2945
Training Accuracy: 0.9541
Validation Accuracy: 0.8944
Duration: 379.07 seconds


Epoch [23/70]
Training Loss: 0.1086
Validation Loss: 0.1678
Training Accuracy: 0.9575
Validation Accuracy: 0.9408
Duration: 379.05 seconds


Epoch [24/70]
Training Loss: 0.1055
Validation Loss: 0.2811
Training Accuracy: 0.9588
Validation Accuracy: 0.9024
Duration: 378.95 seconds


Epoch [25/70]
Training Loss: 0.0984
Validation Loss: 0.1753
Training Accuracy: 0.9615
Validation Accuracy: 0.9360
Duration: 379.11 seconds


Epoch [26/70]
Training Loss: 0.0944
Validation Loss: 0.1772
Training Accuracy: 0.9639
Validation Accuracy: 0.9384
Duration: 379.34 seconds


Epoch [27/70]
Training Loss: 0.0904
Validation Loss: 0.1578
Training Accuracy: 0.9646
Validation Accuracy: 0.9408
Duration: 380.52 seconds


Early stopping triggered after epoch 27.



Training duration: 10360.04 seconds
