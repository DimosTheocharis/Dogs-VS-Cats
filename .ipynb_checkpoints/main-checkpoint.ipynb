{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f46ffdc",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a63f5f",
   "metadata": {},
   "source": [
    "Make sure that all subfolders are loaded and ready to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b115c31",
   "metadata": {},
   "source": [
    "Set autoreload to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de072a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))  # add parent directory (project root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96992de8",
   "metadata": {},
   "source": [
    "Import modules, components, functions etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d42ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from src.utils.basics import displayImage, measureAccuracy, loadModel\n",
    "from src.utils.data import loadData, extractDataFromLoader\n",
    "from src.config import Config\n",
    "from src.cnn import ConvolutionalNeuralNetwork, LayerType, ActivationFunction\n",
    "from src.logger import Logger\n",
    "from src.train import runExperiment\n",
    "from src.test import testModel\n",
    "from src.architectures.small import SmallArchitecture\n",
    "from src.architectures.medium import MediumArchitecture\n",
    "from src.architectures.mediumRegularized import MediumRegularizedArchitecture\n",
    "from src.architectures.doubleBarrelRegularized import DoubleBarrelRegularizedArchitecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22348a92",
   "metadata": {},
   "source": [
    "## Load data for Experiment #A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0017f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainLoader, validationLoader, testLoader = loadData(Config.DATASET_PATH, batchSize=Config.BATCH_SIZE, dataAugmentationTechniques=[\n",
    "#     v2.RandomHorizontalFlip(0.5),\n",
    "#     v2.ColorJitter(brightness=0.25, contrast=0.15, saturation=0.15, hue=0.05),\n",
    "#     v2.RandomAffine(degrees=0, translate=(0.25, 0.25))\n",
    "# ])\n",
    "\n",
    "# # Combine all batches of the validation set into single tensors\n",
    "# validationImages, validationLabels = extractDataFromLoader(validationLoader)\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(validationLabels[i])\n",
    "#     displayImage(validationImages[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d11077d",
   "metadata": {},
   "source": [
    "### Medium architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750abaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ConvolutionalNeuralNetwork(\n",
    "#         architecture=SmallArchitecture(),\n",
    "#         epochs=2,\n",
    "#         learningRate=0.001,\n",
    "#         batchSize=Config.BATCH_SIZE,\n",
    "#         weightDecay=0.0001,\n",
    "#     )\n",
    "\n",
    "# loadModel(model, \"experiments/experiment_01 2025-09-08 15.26/model.pth\")\n",
    "# testModel(model, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649aae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimentId = 2\n",
    "# runExperiment(\n",
    "#     experimentId=experimentId,\n",
    "#     model=ConvolutionalNeuralNetwork(\n",
    "#         architecture=MediumArchitecture(),\n",
    "#         epochs=30,\n",
    "#         learningRate=0.001,\n",
    "#         batchSize=Config.BATCH_SIZE,\n",
    "#         weightDecay=0.0001,\n",
    "#     ),\n",
    "#     trainLoader=trainLoader,\n",
    "#     validationImages=validationImages,\n",
    "#     validationLabels=validationLabels,\n",
    "#     earlyStopping=Config.EARLY_STOPPING\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77987b6b",
   "metadata": {},
   "source": [
    "### Medium architecture with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimentId = 3\n",
    "# runExperiment(\n",
    "#     experimentId=experimentId,\n",
    "#     model=ConvolutionalNeuralNetwork(\n",
    "#         architecture=MediumRegularizedArchitecture(),\n",
    "#         epochs=70,\n",
    "#         learningRate=0.001,\n",
    "#         batchSize=Config.BATCH_SIZE,\n",
    "#         weightDecay=0.0001,\n",
    "#     ),\n",
    "#     trainLoader=trainLoader,\n",
    "#     validationImages=validationImages,\n",
    "#     validationLabels=validationLabels,\n",
    "#     earlyStopping=Config.EARLY_STOPPING\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0681d6ea",
   "metadata": {},
   "source": [
    "### DoubleBarrel with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimentId = 9\n",
    "# runExperiment(\n",
    "#     experimentId=experimentId,\n",
    "#     model=ConvolutionalNeuralNetwork(\n",
    "#         architecture=DoubleBarrelRegularizedArchitecture(),\n",
    "#         epochs=70,\n",
    "#         learningRate=0.001,\n",
    "#         batchSize=Config.BATCH_SIZE,\n",
    "#         weightDecay=0.0001,\n",
    "#     ),\n",
    "#     trainLoader=trainLoader,\n",
    "#     validationImages=validationImages,\n",
    "#     validationLabels=validationLabels,\n",
    "#     earlyStopping=Config.EARLY_STOPPING,\n",
    "#     description=\"\"\"Transformation B: RandomHorizontalFlip, ColorJitter, RandomAffine (translate). Applies data augmentation\n",
    "#         transformations before basic transformations!!\n",
    "#     \"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e9174",
   "metadata": {},
   "source": [
    "# Load data for Experiment #B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef778eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader, validationLoader, testLoader = loadData(Config.DATASET_PATH, batchSize=Config.BATCH_SIZE, dataAugmentationTechniques=[\n",
    "    v2.RandomHorizontalFlip(0.5),\n",
    "    v2.RandomRotation(30)\n",
    "])\n",
    "\n",
    "# Combine all batches of the validation set into single tensors\n",
    "validationImages, validationLabels = extractDataFromLoader(validationLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51bbae",
   "metadata": {},
   "source": [
    "### DoubleBarrel with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentId = 10\n",
    "runExperiment(\n",
    "    experimentId=experimentId,\n",
    "    model=ConvolutionalNeuralNetwork(\n",
    "        architecture=DoubleBarrelRegularizedArchitecture(),\n",
    "        epochs=70,\n",
    "        learningRate=0.001,\n",
    "        batchSize=Config.BATCH_SIZE,\n",
    "        weightDecay=0.0001,\n",
    "    ),\n",
    "    trainLoader=trainLoader,\n",
    "    validationImages=validationImages,\n",
    "    validationLabels=validationLabels,\n",
    "    earlyStopping=Config.EARLY_STOPPING,\n",
    "    description=\"\"\"Transformation C: RandomHorizontalFlip, RandomRotation. Applies data augmentation\n",
    "        transformations before basic transformations!!\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b42438",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d84279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: \n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Predictions: \n",
      "tensor([3.9362e-01, 2.1748e-06, 8.5361e-02, 7.9559e-02, 9.9984e-01, 1.1565e-05,\n",
      "        1.0000e+00, 1.0000e+00, 9.9996e-01, 1.7600e-03, 4.4875e-07, 6.0926e-07,\n",
      "        2.0113e-04, 6.8960e-06, 9.9827e-01, 1.9511e-02, 9.9162e-01, 2.9665e-02,\n",
      "        9.9999e-01, 2.6593e-06, 9.2260e-05, 5.4420e-05, 2.1598e-04, 1.7545e-08,\n",
      "        1.7271e-05, 6.7084e-02, 4.3859e-03, 6.7906e-01, 9.9890e-01, 7.7214e-01,\n",
      "        9.9998e-01, 2.7957e-04, 6.4474e-09, 2.5802e-02, 1.0634e-01, 1.2448e-01,\n",
      "        2.1706e-04, 2.4025e-03, 2.4889e-01])\n",
      "Accuracy on test set: 0.9487\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "trainLoader, validationLoader, testLoader = loadData(Config.DATASET_PATH, batchSize=Config.BATCH_SIZE, dataAugmentationTechniques=[])\n",
    "\n",
    "model=ConvolutionalNeuralNetwork(\n",
    "    architecture=DoubleBarrelRegularizedArchitecture()\n",
    ")\n",
    "\n",
    "loadModel(model, \"experiments/experiment_04 2025-09-20 21.31/model.pth\")\n",
    "\n",
    "testModel(\n",
    "    model,\n",
    "    testLoader=testLoader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2d5b6",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils.basics import imageAugmentation\n",
    "# import torchvision\n",
    "# from torchvision.transforms import v2\n",
    "# from src.config import Config\n",
    "\n",
    "# img = torchvision.io.decode_image(\"C:/Users/dimos/Desktop/Δημοσθένης/7.jpg\").float() / 255\n",
    "\n",
    "\n",
    "# transforms = torchvision.transforms.Compose({\n",
    "#     # v2.RandomResizedCrop(size=Config.IMAGE_SIZE, scale=(0.6, 0.9)),\n",
    "#     # v2.ColorJitter(0.25, 0.15, 0.15, 0.05),\n",
    "#     v2.RandomHorizontalFlip(0.5),\n",
    "#     # v2.RandomRotation(30),\n",
    "#     # v2.GaussianBlur(kernel_size=(7, 13), sigma=(6, 7))\n",
    "#     # v2.RandomAffine(degrees=0, scale=(0.8, 1.3))\n",
    "#     v2.ColorJitter(brightness=(0.75, 1.25), contrast=(0.85, 1.15), saturation=(0.85, 1.15), hue=(-0.05, 0.05)),\n",
    "#     v2.RandomAffine(degrees=0, translate=(0.25, 0.25)),\n",
    "#     v2.Resize((Config.IMAGE_SIZE, Config.IMAGE_SIZE)),\n",
    "#     v2.ToTensor()\n",
    "# })\n",
    "\n",
    "# imageAugmentation(img, transforms, times=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
